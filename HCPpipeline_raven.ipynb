{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data processing pipeline\n",
    "\n",
    "import subprocess\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Three part, fmriprep, ciftify, and HCP Pipeline\n",
    "class Pipeline(object):\n",
    "\n",
    "    def __init__(self, data_inpath, data_outpath, prep_workdir, ciftify_workdir, fsf_dir, subject_id, task='action'):\n",
    "        self.data_inpath = data_inpath\n",
    "        self.data_outpath = data_outpath\n",
    "        self.prep_workdir = prep_workdir\n",
    "        self.subject_id = subject_id\n",
    "        self.task = task\n",
    "        self.ciftify_workdir = ciftify_workdir\n",
    "        self.fsf_dir = fsf_dir\n",
    "\n",
    "    def _decompose_ev(self, subj_id, ses_id, run_id, ev_cond):\n",
    "        \"\"\"\n",
    "        -------------------\n",
    "        Decompose paradigm into different conditions\n",
    "        we promise:\n",
    "        1: const_edge_number\n",
    "        2: const_obj_number\n",
    "        3: const_symbolic_number\n",
    "        4: dist3_edge_number\n",
    "        5: dist3_obj_number\n",
    "        6: dist3_symbolic_number\n",
    "        7: prog_edge_number\n",
    "        8: prog_obj_number\n",
    "        9: prog_symbolic_number\n",
    "        10: visual_stimuli\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        ev_cond[pd.DataFrame]: experimental variable paradigm\n",
    "        \"\"\"\n",
    "        labeldict = {1:'const_edge_number', 2:'const_obj_number', 3:'const_symbolic_number', 4:'dist3_edge_number', 5:'dist3_obj_number', \n",
    "                     6:'dist3_symbolic_number', 7:'prog_edge_number', 8:'prog_obj_number', 9:'prog_symbolic_number', 10:'visual_stimuli'}\n",
    "        #print(np.unique(ev_cond['trial_type']))\n",
    "        #print(np.arange(len(labeldict)))\n",
    "        assert (\n",
    "            np.all(np.unique(ev_cond['trial_type']) == np.arange(1, len(labeldict) + 1))), \"Conditions are not complete.\"\n",
    "        for lbl in labeldict.keys():\n",
    "            ev_cond_tmp = ev_cond[ev_cond['trial_type'] == lbl]\n",
    "            ev_cond_decomp = np.zeros((3, len(ev_cond_tmp)))\n",
    "            ev_cond_decomp[0, :] = np.array(ev_cond_tmp['onset'])\n",
    "            ev_cond_decomp[1, :] = np.array(ev_cond_tmp['duration'])\n",
    "            ev_cond_decomp[2, :] = np.ones(len(ev_cond_tmp))\n",
    "            ev_cond_decomp = ev_cond_decomp.T\n",
    "            outpath = os.path.join(self.ciftify_workdir, subj_id, 'MNINonLinear', 'Results',\n",
    "                                   ses_id + '_' + 'task-' + self.task + '_' + 'run-' + run_id, 'EVs/')\n",
    "            if not os.path.isdir(outpath):\n",
    "                subprocess.call('mkdir ' + outpath, shell=True)\n",
    "                \n",
    "            np.savetxt(os.path.join(outpath, labeldict[lbl] + '.txt'), ev_cond_decomp, fmt='%-6.1f', delimiter='\\t',\n",
    "                       newline='\\n')\n",
    "\n",
    "    def prepare_EVs(self):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        '''\n",
    "        for subj_id in self.subject_id:\n",
    "            # Load ses_id\n",
    "            session_id = os.listdir(os.path.join(self.data_inpath, subj_id))\n",
    "            for ses_id in session_id:\n",
    "                # Load run_id\n",
    "                with open(os.path.join(self.data_inpath, subj_id,\n",
    "                                       ses_id, 'tmp', 'run_info',\n",
    "                                       self.task + '.rlf'), 'r') as f:\n",
    "                    runs_id = f.read().splitlines()\n",
    "        '''\n",
    "        \n",
    "        runs_id = ['01','02','03','04','05','06','07','08']\n",
    "        ciftify_run_id = ['1','2','3','4','5','6','7','8']\n",
    "        subj_id = self.subject_id[0]\n",
    "        ses_id = 'ses-raven'\n",
    "        for i in range(len(runs_id)):\n",
    "            ev_cond = pd.read_csv(os.path.join(self.data_inpath, subj_id, ses_id, 'func',\n",
    "                                                subj_id + '_' + ses_id + '_' + 'task-' + self.task + '_' + 'run-' + runs_id[i] + '_events.tsv'),\n",
    "                                    sep='\\t')\n",
    "            self._decompose_ev(subj_id, ses_id, ciftify_run_id[i], ev_cond)\n",
    "\n",
    "    def _modify_fsf1(self, fsfpath, to_runid, from_runid='run-a'):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        sedfsf1_command = \" \".join(['sed', '-i',\n",
    "                                    '\\'s#{0}#{1}#g\\''.format(from_runid, to_runid), fsfpath])\n",
    "        subprocess.call(sedfsf1_command, shell=True)\n",
    "            \n",
    "    def prepare_fsf(self):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        fsflevel1_indir = os.path.join(self.fsf_dir, 'level1.fsf')\n",
    "        fsflevel2_indir = os.path.join(self.fsf_dir, 'level2.fsf')\n",
    "        for subj_id in self.subject_id:\n",
    "            result_dir = os.path.join(self.ciftify_workdir, subj_id,\n",
    "                                      'MNINonLinear', 'Results')\n",
    "            # Load ses_id\n",
    "            session_id = os.listdir(os.path.join(self.data_inpath, subj_id))\n",
    "            #此时的session_id是ses-raven\n",
    "            #print(session_id)\n",
    "            for ses_id in session_id:\n",
    "                #with open(os.path.join(self.data_inpath, subj_id,\n",
    "                #                       ses_id, 'tmp', 'run_info',\n",
    "                #                       self.task + '.rlf'), 'r') as f:\n",
    "                #    runs_id = f.read().splitlines()\n",
    "                #if len(runs_id) != 6:\n",
    "                #    continue\n",
    "\n",
    "                #这里自己写了runID，覆盖了之前读这个rlf文件的\n",
    "                runs_id = ['1','2','3','4','5','6','7','8']\n",
    "\n",
    "                fsflevel2_outdir = os.path.join(result_dir,\n",
    "                                                ses_id + '_' + 'task-' + self.task)\n",
    "                print(fsflevel2_outdir)\n",
    "                if not os.path.isdir(fsflevel2_outdir):\n",
    "                    os.makedirs(fsflevel2_outdir)\n",
    "\n",
    "                #将fsflevel2复制到对应路径下 \n",
    "                cpfsf2_command = ' '.join(['cp', fsflevel2_indir, os.path.join(fsflevel2_outdir,\n",
    "                                                                               ses_id + '_' + 'task-' + self.task + '_hp200_s4_level2.fsf')])\n",
    "                \n",
    "                self.cpfsf2_commmand = cpfsf2_command\n",
    "                subprocess.call(cpfsf2_command, shell=True)\n",
    "                \n",
    "                for run_id in runs_id:\n",
    "                    fsflevel1_outdir = os.path.join(result_dir,\n",
    "                                                    ses_id + '_' + 'task-' + self.task + '_' + 'run-' + run_id)\n",
    "                    print(fsflevel1_outdir)\n",
    "                    if not os.path.isdir(fsflevel1_outdir):\n",
    "                        os.makedirs(fsflevel1_outdir)\n",
    "                    cpfsf1_command = ' '.join(['cp', fsflevel1_indir, os.path.join(fsflevel1_outdir,\n",
    "                                                                                   ses_id + '_' + 'task-' + self.task + '_' + 'run-' + run_id + '_hp200_s4_level1.fsf')])\n",
    "                    subprocess.call(cpfsf1_command, shell=True)\n",
    "                    self._modify_fsf1(os.path.join(fsflevel1_outdir,\n",
    "                                                   ses_id + '_' + 'task-' + self.task + '_' + 'run-' + run_id + '_hp200_s4_level1.fsf'),\n",
    "                                      'run-' + run_id)\n",
    "\n",
    "    def run_taskglm(self):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        lowres = '32'\n",
    "        grayres = '2'\n",
    "        origFWHM = '2'\n",
    "        confound = 'NONE'\n",
    "        finalFWHM = '4'\n",
    "        #tempfilter = '200'\n",
    "        vba = 'NO'\n",
    "        regname = 'NONE'\n",
    "        parcellation = 'NONE'\n",
    "        parcefile = 'NONE'\n",
    "        for subj_id in self.subject_id:\n",
    "            # Load ses_id\n",
    "            session_id = os.listdir(os.path.join(self.data_inpath, subj_id))\n",
    "            lvl2task_list = []\n",
    "            for ses_id in session_id:\n",
    "                lvl2task_list.append(ses_id + '_' + 'task-' + self.task)\n",
    "                # Load run_id\n",
    "                #with open(os.path.join(self.data_inpath, subj_id,\n",
    "                #                       ses_id, 'tmp', 'run_info',\n",
    "                #                       self.task + '.rlf'), 'r') as f:\n",
    "                #    runs_id = f.read().splitlines()\n",
    "\n",
    "                #这里自己写了runID，覆盖了之前读这个rlf文件的\n",
    "                runs_id = ['1','2','3','4','5','6','7','8']\n",
    "                \n",
    "                lvl1tasks_list = []\n",
    "                for run_id in runs_id:\n",
    "                    # prepare lvl1tasks\n",
    "                    lvl1tasks_list.append(ses_id + '_' + 'task-' + self.task + '_' + 'run-' + run_id)\n",
    "                lvl1tasks = '@'.join(lvl1tasks_list)\n",
    "                lvl1fsfs = lvl1tasks\n",
    "            lvl2task = '@'.join(lvl2task_list)\n",
    "            lvl2fsf = 'ses-raven_task-raven_'\n",
    "\n",
    "            enter_setup_scriptdir_command = ' '.join(['cd',\n",
    "                                                      '/nfs/h1/userhome/liyifan/workingdir/Raven-fmri/HCPpipelines/HCPpipelines-master/Examples/Scripts/'])\n",
    "            #source_command =' '.join(['source',\n",
    "            #                          'SetUpHCPPipeline.sh'])\n",
    "            #source_command = 'source SetUpHCPPipeline.sh'\n",
    "            #subprocess.check_output(['bash', '-c', source_command])\n",
    "            #source_command = './source_script.sh'\n",
    "\n",
    "            enter_hcp_pipeline_task_analysis_command = ' '.join (['cd',\n",
    "                                                                  '/nfs/h1/userhome/liyifan/workingdir/Raven-fmri/HCPpipelines/HCPpipelines-master/TaskfMRIAnalysis/'])\n",
    "            \n",
    "            export_HCPPIPEDIR_command = ' '.join(['export',\n",
    "                                                  'HCPPIPEDIR=/nfs/h1/userhome/liyifan/workingdir/Raven-fmri/HCPpipelines/HCPpipelines-master'])\n",
    "\n",
    "            taskglm_command = ' '.join(['./TaskfMRIAnalysis.sh',\n",
    "                                        '--study-folder=' + self.ciftify_workdir,\n",
    "                                        '--subject=' + subj_id,\n",
    "                                        '--lvl1tasks=' + lvl1tasks,\n",
    "                                        '--lvl1fsfs=' + lvl1fsfs,\n",
    "                                        '--lvl2task=' + lvl2task,\n",
    "                                        '--lvl2fsf=' + lvl2fsf,\n",
    "                                        '--lowresmesh=' + lowres,\n",
    "                                        '--grayordinatesres=' + grayres,\n",
    "                                        '--origsmoothingFWHM=' + origFWHM,\n",
    "                                        '--confound=' + confound,\n",
    "                                        '--finalsmoothingFWHM=' + finalFWHM,\n",
    "                                        #'--temporalfilter=' + tempfilter,\n",
    "                                        '--vba=' + vba,\n",
    "                                        '--regname=' + regname,\n",
    "                                        '--parcellation=' + parcellation,\n",
    "                                        '--parcellationfile=' + parcefile])\n",
    "            # self.taskglm_command = taskglm_command\n",
    "            try:\n",
    "                #subprocess.run('source ~/.bashrc',shell=True)\n",
    "                subprocess.check_call(enter_setup_scriptdir_command, shell=True)\n",
    "                subprocess.check_call(export_HCPPIPEDIR_command, shell=True)\n",
    "                #subprocess.check_call(source_command, shell=True)\n",
    "\n",
    "                subprocess.run(['source','SetUpHCPPipeline.sh'])\n",
    "                subprocess.check_call(enter_hcp_pipeline_task_analysis_command, shell=True)\n",
    "                #print(taskglm_command)\n",
    "                subprocess.check_call(taskglm_command, shell=True)\n",
    "                \n",
    "\n",
    "\n",
    "            except subprocess.CalledProcessError:\n",
    "                raise Exception('TASKGLM: Error happened in subject {}'.format(subj_id))\n",
    "\n",
    "    def run_pipeline(self):\n",
    "        #self.run_fmriprep()\n",
    "        #self.run_fslreg()\n",
    "        #self.run_ciftify()\n",
    "        self.prepare_EVs()\n",
    "        self.prepare_fsf()\n",
    "        self.run_taskglm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/nfs/t2/raven/data/bold/derivatives/ciftify/sub-02/MNINonLinear/Results/ses-raven_task-action\n",
      "/nfs/t2/raven/data/bold/derivatives/ciftify/sub-02/MNINonLinear/Results/ses-raven_task-action_run-1\n",
      "/nfs/t2/raven/data/bold/derivatives/ciftify/sub-02/MNINonLinear/Results/ses-raven_task-action_run-2\n",
      "/nfs/t2/raven/data/bold/derivatives/ciftify/sub-02/MNINonLinear/Results/ses-raven_task-action_run-3\n",
      "/nfs/t2/raven/data/bold/derivatives/ciftify/sub-02/MNINonLinear/Results/ses-raven_task-action_run-4\n",
      "/nfs/t2/raven/data/bold/derivatives/ciftify/sub-02/MNINonLinear/Results/ses-raven_task-action_run-5\n",
      "/nfs/t2/raven/data/bold/derivatives/ciftify/sub-02/MNINonLinear/Results/ses-raven_task-action_run-6\n",
      "/nfs/t2/raven/data/bold/derivatives/ciftify/sub-02/MNINonLinear/Results/ses-raven_task-action_run-7\n",
      "/nfs/t2/raven/data/bold/derivatives/ciftify/sub-02/MNINonLinear/Results/ses-raven_task-action_run-8\n",
      "/nfs/t2/raven/data/bold/derivatives/ciftify/sub-03/MNINonLinear/Results/ses-raven_task-action\n",
      "/nfs/t2/raven/data/bold/derivatives/ciftify/sub-03/MNINonLinear/Results/ses-raven_task-action_run-1\n",
      "/nfs/t2/raven/data/bold/derivatives/ciftify/sub-03/MNINonLinear/Results/ses-raven_task-action_run-2\n",
      "/nfs/t2/raven/data/bold/derivatives/ciftify/sub-03/MNINonLinear/Results/ses-raven_task-action_run-3\n",
      "/nfs/t2/raven/data/bold/derivatives/ciftify/sub-03/MNINonLinear/Results/ses-raven_task-action_run-4\n",
      "/nfs/t2/raven/data/bold/derivatives/ciftify/sub-03/MNINonLinear/Results/ses-raven_task-action_run-5\n",
      "/nfs/t2/raven/data/bold/derivatives/ciftify/sub-03/MNINonLinear/Results/ses-raven_task-action_run-6\n",
      "/nfs/t2/raven/data/bold/derivatives/ciftify/sub-03/MNINonLinear/Results/ses-raven_task-action_run-7\n",
      "/nfs/t2/raven/data/bold/derivatives/ciftify/sub-03/MNINonLinear/Results/ses-raven_task-action_run-8\n",
      "/nfs/t2/raven/data/bold/derivatives/ciftify/sub-04/MNINonLinear/Results/ses-raven_task-action\n",
      "/nfs/t2/raven/data/bold/derivatives/ciftify/sub-04/MNINonLinear/Results/ses-raven_task-action_run-1\n",
      "/nfs/t2/raven/data/bold/derivatives/ciftify/sub-04/MNINonLinear/Results/ses-raven_task-action_run-2\n",
      "/nfs/t2/raven/data/bold/derivatives/ciftify/sub-04/MNINonLinear/Results/ses-raven_task-action_run-3\n",
      "/nfs/t2/raven/data/bold/derivatives/ciftify/sub-04/MNINonLinear/Results/ses-raven_task-action_run-4\n",
      "/nfs/t2/raven/data/bold/derivatives/ciftify/sub-04/MNINonLinear/Results/ses-raven_task-action_run-5\n",
      "/nfs/t2/raven/data/bold/derivatives/ciftify/sub-04/MNINonLinear/Results/ses-raven_task-action_run-6\n",
      "/nfs/t2/raven/data/bold/derivatives/ciftify/sub-04/MNINonLinear/Results/ses-raven_task-action_run-7\n",
      "/nfs/t2/raven/data/bold/derivatives/ciftify/sub-04/MNINonLinear/Results/ses-raven_task-action_run-8\n",
      "/nfs/t2/raven/data/bold/derivatives/ciftify/sub-05/MNINonLinear/Results/ses-raven_task-action\n",
      "/nfs/t2/raven/data/bold/derivatives/ciftify/sub-05/MNINonLinear/Results/ses-raven_task-action_run-1\n",
      "/nfs/t2/raven/data/bold/derivatives/ciftify/sub-05/MNINonLinear/Results/ses-raven_task-action_run-2\n",
      "/nfs/t2/raven/data/bold/derivatives/ciftify/sub-05/MNINonLinear/Results/ses-raven_task-action_run-3\n",
      "/nfs/t2/raven/data/bold/derivatives/ciftify/sub-05/MNINonLinear/Results/ses-raven_task-action_run-4\n",
      "/nfs/t2/raven/data/bold/derivatives/ciftify/sub-05/MNINonLinear/Results/ses-raven_task-action_run-5\n",
      "/nfs/t2/raven/data/bold/derivatives/ciftify/sub-05/MNINonLinear/Results/ses-raven_task-action_run-6\n",
      "/nfs/t2/raven/data/bold/derivatives/ciftify/sub-05/MNINonLinear/Results/ses-raven_task-action_run-7\n",
      "/nfs/t2/raven/data/bold/derivatives/ciftify/sub-05/MNINonLinear/Results/ses-raven_task-action_run-8\n",
      "/nfs/t2/raven/data/bold/derivatives/ciftify/sub-06/MNINonLinear/Results/ses-raven_task-action\n",
      "/nfs/t2/raven/data/bold/derivatives/ciftify/sub-06/MNINonLinear/Results/ses-raven_task-action_run-1\n",
      "/nfs/t2/raven/data/bold/derivatives/ciftify/sub-06/MNINonLinear/Results/ses-raven_task-action_run-2\n",
      "/nfs/t2/raven/data/bold/derivatives/ciftify/sub-06/MNINonLinear/Results/ses-raven_task-action_run-3\n",
      "/nfs/t2/raven/data/bold/derivatives/ciftify/sub-06/MNINonLinear/Results/ses-raven_task-action_run-4\n",
      "/nfs/t2/raven/data/bold/derivatives/ciftify/sub-06/MNINonLinear/Results/ses-raven_task-action_run-5\n",
      "/nfs/t2/raven/data/bold/derivatives/ciftify/sub-06/MNINonLinear/Results/ses-raven_task-action_run-6\n",
      "/nfs/t2/raven/data/bold/derivatives/ciftify/sub-06/MNINonLinear/Results/ses-raven_task-action_run-7\n",
      "/nfs/t2/raven/data/bold/derivatives/ciftify/sub-06/MNINonLinear/Results/ses-raven_task-action_run-8\n",
      "/nfs/t2/raven/data/bold/derivatives/ciftify/sub-07/MNINonLinear/Results/ses-raven_task-action\n",
      "/nfs/t2/raven/data/bold/derivatives/ciftify/sub-07/MNINonLinear/Results/ses-raven_task-action_run-1\n",
      "/nfs/t2/raven/data/bold/derivatives/ciftify/sub-07/MNINonLinear/Results/ses-raven_task-action_run-2\n",
      "/nfs/t2/raven/data/bold/derivatives/ciftify/sub-07/MNINonLinear/Results/ses-raven_task-action_run-3\n",
      "/nfs/t2/raven/data/bold/derivatives/ciftify/sub-07/MNINonLinear/Results/ses-raven_task-action_run-4\n",
      "/nfs/t2/raven/data/bold/derivatives/ciftify/sub-07/MNINonLinear/Results/ses-raven_task-action_run-5\n",
      "/nfs/t2/raven/data/bold/derivatives/ciftify/sub-07/MNINonLinear/Results/ses-raven_task-action_run-6\n",
      "/nfs/t2/raven/data/bold/derivatives/ciftify/sub-07/MNINonLinear/Results/ses-raven_task-action_run-7\n",
      "/nfs/t2/raven/data/bold/derivatives/ciftify/sub-07/MNINonLinear/Results/ses-raven_task-action_run-8\n",
      "/nfs/t2/raven/data/bold/derivatives/ciftify/sub-08/MNINonLinear/Results/ses-raven_task-action\n",
      "/nfs/t2/raven/data/bold/derivatives/ciftify/sub-08/MNINonLinear/Results/ses-raven_task-action_run-1\n",
      "/nfs/t2/raven/data/bold/derivatives/ciftify/sub-08/MNINonLinear/Results/ses-raven_task-action_run-2\n",
      "/nfs/t2/raven/data/bold/derivatives/ciftify/sub-08/MNINonLinear/Results/ses-raven_task-action_run-3\n",
      "/nfs/t2/raven/data/bold/derivatives/ciftify/sub-08/MNINonLinear/Results/ses-raven_task-action_run-4\n",
      "/nfs/t2/raven/data/bold/derivatives/ciftify/sub-08/MNINonLinear/Results/ses-raven_task-action_run-5\n",
      "/nfs/t2/raven/data/bold/derivatives/ciftify/sub-08/MNINonLinear/Results/ses-raven_task-action_run-6\n",
      "/nfs/t2/raven/data/bold/derivatives/ciftify/sub-08/MNINonLinear/Results/ses-raven_task-action_run-7\n",
      "/nfs/t2/raven/data/bold/derivatives/ciftify/sub-08/MNINonLinear/Results/ses-raven_task-action_run-8\n",
      "/nfs/t2/raven/data/bold/derivatives/ciftify/sub-09/MNINonLinear/Results/ses-raven_task-action\n",
      "/nfs/t2/raven/data/bold/derivatives/ciftify/sub-09/MNINonLinear/Results/ses-raven_task-action_run-1\n",
      "/nfs/t2/raven/data/bold/derivatives/ciftify/sub-09/MNINonLinear/Results/ses-raven_task-action_run-2\n",
      "/nfs/t2/raven/data/bold/derivatives/ciftify/sub-09/MNINonLinear/Results/ses-raven_task-action_run-3\n",
      "/nfs/t2/raven/data/bold/derivatives/ciftify/sub-09/MNINonLinear/Results/ses-raven_task-action_run-4\n",
      "/nfs/t2/raven/data/bold/derivatives/ciftify/sub-09/MNINonLinear/Results/ses-raven_task-action_run-5\n",
      "/nfs/t2/raven/data/bold/derivatives/ciftify/sub-09/MNINonLinear/Results/ses-raven_task-action_run-6\n",
      "/nfs/t2/raven/data/bold/derivatives/ciftify/sub-09/MNINonLinear/Results/ses-raven_task-action_run-7\n",
      "/nfs/t2/raven/data/bold/derivatives/ciftify/sub-09/MNINonLinear/Results/ses-raven_task-action_run-8\n",
      "/nfs/t2/raven/data/bold/derivatives/ciftify/sub-11/MNINonLinear/Results/ses-raven_task-action\n",
      "/nfs/t2/raven/data/bold/derivatives/ciftify/sub-11/MNINonLinear/Results/ses-raven_task-action_run-1\n",
      "/nfs/t2/raven/data/bold/derivatives/ciftify/sub-11/MNINonLinear/Results/ses-raven_task-action_run-2\n",
      "/nfs/t2/raven/data/bold/derivatives/ciftify/sub-11/MNINonLinear/Results/ses-raven_task-action_run-3\n",
      "/nfs/t2/raven/data/bold/derivatives/ciftify/sub-11/MNINonLinear/Results/ses-raven_task-action_run-4\n",
      "/nfs/t2/raven/data/bold/derivatives/ciftify/sub-11/MNINonLinear/Results/ses-raven_task-action_run-5\n",
      "/nfs/t2/raven/data/bold/derivatives/ciftify/sub-11/MNINonLinear/Results/ses-raven_task-action_run-6\n",
      "/nfs/t2/raven/data/bold/derivatives/ciftify/sub-11/MNINonLinear/Results/ses-raven_task-action_run-7\n",
      "/nfs/t2/raven/data/bold/derivatives/ciftify/sub-11/MNINonLinear/Results/ses-raven_task-action_run-8\n"
     ]
    }
   ],
   "source": [
    "data_inpath = '/nfs/t2/raven/data/bold/nifti/'\n",
    "data_outpath = '/nfs/t2/raven/data/bold/derivatives/fmriprep/'\n",
    "ciftify_workdir = '/nfs/t2/raven/data/bold/derivatives/ciftify'\n",
    "# fsf_dir = os.path.join(data_inpath, 'fsf_template')\n",
    "fsf_dir = '/nfs/h1/userhome/liyifan/workingdir/Raven-fmri/fsf/f-test/'\n",
    "\n",
    "prep_workdir = '/nfs/e4/function_guided_resection/fmriprep_tmp_ms/'\n",
    "\n",
    "#participants_info = pd.read_csv(os.path.join(data_inpath, 'participants.tsv'), sep='\\t')\n",
    "#subject_id = participants_info['participant_id'].values\n",
    "# run the first 8 participants in this terminal\n",
    "# subject_id = subject_id[4+30:4+40]\n",
    "sub_flag = ['sub-02','sub-03','sub-04','sub-05','sub-06','sub-07','sub-08','sub-09','sub-11']\n",
    "for sub in sub_flag:\n",
    "    subject_id = [sub]\n",
    "    pip_cls = Pipeline(data_inpath, data_outpath, prep_workdir, ciftify_workdir, fsf_dir, subject_id)\n",
    "    pip_cls.prepare_EVs()\n",
    "    pip_cls.prepare_fsf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
