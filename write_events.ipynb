{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from os.path import join as pjoin\n",
    "import nibabel as nib\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = './data/'\n",
    "RUN_NUM = 8\n",
    "RUN_PROB_NUM = 27\n",
    "Numerical_IDX = range(18,27)\n",
    "subList = ['luomanqi']\n",
    "subjects = ['sub-24']\n",
    "CLASS_NUM = 9\n",
    "ATTRIBUTE=[[0,4,5],[1,2,3],[6,7,8]]#edge,obj,symbolic\n",
    "RULE = [[0,1,6],[2,4,7],[3,5,8]]#const,dist3,prog\n",
    "problem_sequence=[\n",
    "    \"const_edge_number\",\n",
    "    \"const_obj_number\",\n",
    "    \"dist3_obj_number\",\n",
    "    \"prog_obj_number\",\n",
    "    \"dist3_edge_number\",\n",
    "    \"prog_edge_number\",\n",
    "    \"const_symbolic_number\",\n",
    "    \"dist3_symbolic_number\",\n",
    "    \"prog_symbolic_number\"\n",
    "]\n",
    "CLASS_DICT ={\n",
    "    'attribute':['edge','obj','symbolic'],\n",
    "    'rule':['const','dist3','prog']\n",
    "} \n",
    "factor_dict ={'const_edge_number':1,'const_obj_number':2,\n",
    "'const_symbolic_number':3,'dist3_edge_number':4,'dist3_obj_number':5, \n",
    "'dist3_symbolic_number':6,'prog_edge_number':7,'prog_obj_number':8,'prog_symbolic_number':9}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_txt_filename(subID):#查找是否有补run的情况\n",
    "    start_of_filename = f'{subList[subID]}run'\n",
    "    num=0\n",
    "    for file in os.listdir('trial_type/'):\n",
    "        if file.startswith(start_of_filename):\n",
    "            num+=1\n",
    "    return num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sub_problem_idx(subID):\n",
    "    \n",
    "    path = 'trial_type/' + subList[subID] + 'run.txt'\n",
    "    run_file = open(path, 'r+')\n",
    "\n",
    "    run_lst = [int(i) for i in list(run_file.readline())[:-1]]\n",
    "    idx_final = []\n",
    "    for i in range(RUN_NUM):\n",
    "        idx_final.append([int(j) for j in run_file.readline().split(',')])\n",
    "    idx_final = np.array(idx_final)\n",
    "    time_lst = []\n",
    "    for i in range(RUN_NUM):\n",
    "        time_lst.append([int(j) for j in run_file.readline().split(',')])\n",
    "    time_lst = np.array(time_lst)\n",
    "    time_lst = time_lst.reshape(RUN_NUM, RUN_PROB_NUM, 2)\n",
    "    while True:\n",
    "        line = run_file.readline()\n",
    "        if line == '':\n",
    "            break\n",
    "    if get_txt_filename(subID)==2:#加上补做的run\n",
    "        path = 'trial_type/' + subList[subID]+'run2.txt'\n",
    "        run_file2 = open(path, 'r+')\n",
    "\n",
    "        run_lst2 = [int(i) for i in list(run_file2.readline())[:-1]]\n",
    "        run_lst2.remove(0)#会将10解析成1，0因此删除0\n",
    "        run_lst2[run_lst2.index(1)] = 10\n",
    "        idx_final2 = []\n",
    "        for i in range(2):\n",
    "            idx_final2.append([int(j) for j in run_file2.readline().split(',')])\n",
    "        idx_final2 = np.array(idx_final2)\n",
    "        time_lst2 = []\n",
    "        for i in range(2):\n",
    "            time_lst2.append([int(j) for j in run_file2.readline().split(',')])\n",
    "        time_lst2 = np.array(time_lst2)\n",
    "        time_lst2 = time_lst2.reshape(2, RUN_PROB_NUM, 2)\n",
    "        while True:\n",
    "            line = run_file2.readline()\n",
    "            if line == '':\n",
    "                break\n",
    "        \n",
    "        run_lst = run_lst+run_lst2       \n",
    "        idx_final = np.vstack([idx_final,idx_final2])       \n",
    "        time_lst = np.vstack([time_lst,time_lst2])\n",
    "    return run_lst,idx_final,time_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_one_sub_factors(subID):\n",
    "    #输出run_num*problem_num*meta_length(一般是8*27)\n",
    "    run_lst,idx_final,time_lst = get_sub_problem_idx(subID)\n",
    "\n",
    "    # print(run_lst)#用于检查输出run的次序是否有遗漏\n",
    "    run_problem_meta = []\n",
    "    for i in range(len(run_lst)):\n",
    "        problem_lst = idx_final[run_lst[i]-1]//3\n",
    "        # print(idx_final[run_lst[i]-1])\n",
    "        problem_meta = []\n",
    "        for j in range(len(problem_lst)):\n",
    "            class_name = problem_sequence[problem_lst[j]]\n",
    "            class_meta = factor_dict[class_name]\n",
    "            # print(class_name,class_meta)\n",
    "            problem_meta.append(class_meta)\n",
    "        problem_meta=np.array(problem_meta)\n",
    "        run_problem_meta.append(problem_meta)\n",
    "    run_problem_meta=np.array(run_problem_meta)\n",
    "    return run_problem_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(get_one_sub_factors(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8, 1, 7, 2, 6, 5, 3, 4, 9, 2, 3, 4, 6, 5, 8, 7, 1, 9, 2, 3, 8, 7,\n",
       "        1, 4, 5, 6, 9],\n",
       "       [3, 5, 4, 8, 2, 6, 1, 7, 9, 3, 6, 7, 2, 4, 5, 8, 1, 9, 6, 7, 2, 5,\n",
       "        1, 4, 3, 8, 9],\n",
       "       [8, 6, 5, 3, 7, 1, 4, 2, 9, 2, 8, 4, 5, 7, 1, 6, 3, 9, 5, 3, 1, 7,\n",
       "        2, 6, 8, 4, 9],\n",
       "       [2, 6, 8, 4, 1, 5, 3, 7, 9, 5, 4, 3, 8, 6, 2, 1, 7, 9, 4, 6, 5, 2,\n",
       "        3, 7, 1, 8, 9],\n",
       "       [8, 6, 5, 4, 2, 3, 7, 1, 9, 1, 4, 7, 5, 3, 6, 8, 2, 9, 1, 5, 6, 4,\n",
       "        2, 8, 3, 7, 9],\n",
       "       [5, 1, 7, 4, 8, 2, 6, 3, 9, 2, 5, 7, 4, 6, 1, 8, 3, 9, 2, 3, 8, 7,\n",
       "        5, 6, 4, 1, 9],\n",
       "       [4, 6, 7, 8, 5, 2, 1, 3, 9, 1, 7, 3, 5, 4, 8, 2, 6, 9, 4, 5, 1, 7,\n",
       "        3, 8, 2, 6, 9],\n",
       "       [3, 4, 1, 8, 2, 7, 6, 5, 9, 2, 3, 5, 8, 7, 4, 1, 6, 9, 8, 4, 6, 3,\n",
       "        1, 2, 5, 7, 9]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_one_sub_factors(0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prepare_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_run_info_path = '/nfs/t2/raven/data/code/sub_run_info/'\n",
    "nifti_path = '/nfs/t2/raven/data/bold/nifti/'\n",
    "within_sub_path = 'ses-raven/func/'\n",
    "runs = ['run-01','run-02','run-03','run-04','run-05','run-06','run-07','run-08']\n",
    "abs_events_paths = []\n",
    "abs_info_paths = []\n",
    "sort_abs_info_paths = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare events file path\n",
    "for subject in subjects:\n",
    "    tmp = pjoin(nifti_path,subject)\n",
    "    tmp = pjoin(tmp,within_sub_path)\n",
    "    run_paths = []\n",
    "    for run in runs:\n",
    "        file_name = '{}_ses-raven_task-action_{}_events.tsv'.format(subject,run)\n",
    "        run_path = pjoin(tmp,file_name)\n",
    "        #print(run_path)\n",
    "        run_paths.append(run_path)\n",
    "    abs_events_paths.append(run_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare experiment info path\n",
    "for subject in subjects:\n",
    "    tmp = pjoin(sub_run_info_path,subject)\n",
    "    run_paths = []\n",
    "    for run in os.listdir(tmp):\n",
    "        run_paths.append(pjoin(tmp,run))\n",
    "    abs_info_paths.append(run_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sub in abs_info_paths:\n",
    "    sub.sort(key=lambda x: int(x[x.find('Run')+3]))\n",
    "    sort_abs_info_paths.append(sub)      "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "find factors of each trial"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read csv as Dataframe"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "先做一个被试内，8个run的events读写"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['response_time', 'stim_file', 'TODO -- fill in rows and add more tab-separated columns if desired'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-73374f48689d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mevent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_event\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0mevent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'response_time'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'stim_file'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'TODO -- fill in rows and add more tab-separated columns if desired'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mevent\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'onset'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0monset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   5397\u001b[0m                 \u001b[0mweight\u001b[0m  \u001b[0;36m1.0\u001b[0m     \u001b[0;36m0.8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5398\u001b[0m         \"\"\"\n\u001b[0;32m-> 5399\u001b[0;31m         return super().drop(\n\u001b[0m\u001b[1;32m   5400\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5401\u001b[0m             \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4503\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4504\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4505\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4507\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[1;32m   4544\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4545\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4546\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4547\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_axis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   6932\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6933\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6934\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{list(labels[mask])} not found in axis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6935\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6936\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['response_time', 'stim_file', 'TODO -- fill in rows and add more tab-separated columns if desired'] not found in axis\""
     ]
    }
   ],
   "source": [
    "# 0 是指第0个被试\n",
    "for runNum in range(len(sort_abs_info_paths[0])):\n",
    "    test_info = sort_abs_info_paths[0][runNum]\n",
    "    #test_info = '/nfs/h1/userhome/liyifan/workingdir/gongzhenxin_run8.csv'\n",
    "    test_event = abs_events_paths[0][runNum]\n",
    "    #test_event = '/nfs/t2/RAVEN/data/bold/nifti/sub-02/ses-raven/func/sub-02_ses-raven_task-raven_run-08_events.tsv'\n",
    "    info = pd.read_csv(test_info)\n",
    "    trial_start_time = info['problem0.started'][3:30].to_list()\n",
    "    trial_end_time = info['answer2.stopped'][3:30].to_list()\n",
    "    scan_start_time = info['key_resp_2.stopped'][2]\n",
    "    timepoint_list = []\n",
    "    timepoint_list.extend(trial_start_time)\n",
    "\n",
    "    onset = []\n",
    "    for i in range (len(timepoint_list)):\n",
    "        onsetpoint = timepoint_list[i] - scan_start_time\n",
    "        onset.append(round(onsetpoint,3))\n",
    "           \n",
    "    #add visual stimuli onset\n",
    "    for i in range (len(timepoint_list)):\n",
    "        onsetpoint = timepoint_list[i] - scan_start_time\n",
    "        onset.append(round(onsetpoint,3))\n",
    "\n",
    "    duration = []\n",
    "    for i in range(len(trial_start_time)):\n",
    "        trial_time = trial_end_time[i] - trial_start_time[i]\n",
    "        duration.append(round(trial_time,3))\n",
    "        \n",
    "    # add visual stimuli time  \n",
    "    for i in range (len(trial_start_time)):\n",
    "        duration.append(0.1)\n",
    "            \n",
    "    # add visual stimuli type\n",
    "    visual_stimuli_type = np.ones(27,dtype=int)*10\n",
    "\n",
    "    #trial_type = np.concatenate((get_one_sub_factors(0)[runNum],visual_stimuli_type))\n",
    "\n",
    "    # this is where we adjust the wrong runs\n",
    "    if runNum != 0:\n",
    "        trial_type = np.concatenate((get_one_sub_factors(0)[runNum],visual_stimuli_type))\n",
    "    if runNum == 0:\n",
    "        trial_type = np.concatenate((get_one_sub_factors(0)[8],visual_stimuli_type))\n",
    "\n",
    "    event = pd.read_csv(test_event,sep='\\t')\n",
    "    event = event.drop(columns=['response_time','stim_file','TODO -- fill in rows and add more tab-separated columns if desired'])\n",
    "\n",
    "    event['onset'] = onset\n",
    "    event['duration'] = duration\n",
    "    event['trial_type'] = trial_type\n",
    "\n",
    "    event.to_csv(test_event,sep='\\t',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
